{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from random import uniform\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"russian\") + [\"всё\", \"самый\", \"это\"]\n",
    "\n",
    "punctuation += \"–«»…\"\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём с Кинопоиска отзывы на фильмы одного жанра, например, ужасы. Всего 20 фильмов, на каждый возьмём по 10 хороших и 10 плохих отзывов. Из 200 хороших отзывов на 190 соберём данные, на 10 проверим, так же для плохих отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_links = [\"https://www.kinopoisk.ru/film/1178137/reviews/?ord=rating&status=\", \n",
    "             \"https://www.kinopoisk.ru/film/1122138/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/944708/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/804697/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/686898/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/1044906/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/279095/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/915111/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/966995/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/468994/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/261005/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/160931/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/721153/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/930534/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/495892/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/419209/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/695548/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/991225/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/1112132/reviews/?ord=rating&status=\",\n",
    "             \"https://www.kinopoisk.ru/film/404366/reviews/?ord=rating&status=\"]\n",
    "\n",
    "\n",
    "negative_rev_links = [rev+\"bad\" for rev in rev_links]\n",
    "positive_rev_links = [rev+\"good\" for rev in rev_links]\n",
    "\n",
    "# Солнцестояние\n",
    "# Мы \n",
    "# Прочь\n",
    "# Оно / It Follows 2014\n",
    "# Оно 2 \n",
    "# Тихое место\n",
    "# Кладбище домашних животных\n",
    "# Лекарство от здоровья\n",
    "# Живое\n",
    "# Заклятие\n",
    "# Последний дом слева\n",
    "# У холмов есть глаза\n",
    "# Багровый пик\n",
    "# Сплит\n",
    "# Астрал\n",
    "# Хижина в лесу\n",
    "# Чужой: Завет\n",
    "# Проклятие монахини\n",
    "# Реинкарнация\n",
    "# Паранормальное явление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(rev_links):    \n",
    "    \n",
    "    reviews = []\n",
    "    c = 0\n",
    "    \n",
    "    for film_reviews in tqdm(rev_links):\n",
    "        \n",
    "        sleep(uniform(30, 50))\n",
    "        \n",
    "        headers = {'User-Agent': ua.random}\n",
    "        r = requests.get(film_reviews, headers=headers)        \n",
    "        soup = BeautifulSoup(r.text)\n",
    "\n",
    "        reviews += soup.find_all('span', {'class':'_reachbanner_'})\n",
    "\n",
    "        for i in range(10): # на одной странице 10 отзывов\n",
    "            reviews[c*10+i] = re.sub(\"<.*?>|\\s{1,}\", \" \", str(reviews[c*10+i]))\n",
    "         \n",
    "        #for i in range(len(reviews)): # на одной странице все отзывы\n",
    "        #    reviews[i] = re.sub(\"<.*?>|\\s{1,}\", \" \", str(reviews[i]))\n",
    "            \n",
    "        c += 1\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [13:39<00:00, 40.98s/it]\n"
     ]
    }
   ],
   "source": [
    "negative_reviews = get_reviews(negative_rev_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [13:10<00:00, 39.52s/it]\n"
     ]
    }
   ],
   "source": [
    "positive_reviews = get_reviews(positive_rev_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews), len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas_counter(reviews):\n",
    "    \n",
    "    lemmas = []\n",
    "    \n",
    "    for review in reviews:\n",
    "\n",
    "        review = review.lower().translate(str.maketrans('', '', punctuation))\n",
    "        review = re.sub('\\d+', '', review)\n",
    "        review = re.sub('\\s{2,}', ' ', review)\n",
    "        review = word_tokenize(review.lower())\n",
    "\n",
    "        for word in review:\n",
    "            lemma = morph.parse(word)[0].normal_form\n",
    "            if lemma not in sw:\n",
    "                lemmas += [lemma]\n",
    "\n",
    "        \n",
    "    lemmas = Counter(lemmas)\n",
    "            \n",
    "            \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_lemmas_counter = get_lemmas_counter(negative_reviews[:190])\n",
    "positive_lemmas_counter = get_lemmas_counter(positive_reviews[:190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare(lemmas):\n",
    "    \n",
    "    count = {k:v for k,v in lemmas.items() if v > 25}\n",
    "    count = Counter(count)\n",
    "    \n",
    "    return count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_neg_counter = remove_rare(negative_lemmas_counter)\n",
    "total_pos_counter = remove_rare(positive_lemmas_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lemmas = [i[0] for i in total_pos_counter]\n",
    "negative_lemmas = [i[0] for i in total_neg_counter]\n",
    "\n",
    "# ищем слова, которые встречаются только в положительных/отрицательных отзывах\n",
    "\n",
    "excl_positive_lemmas = [i for i in positive_lemmas if i not in negative_lemmas]\n",
    "excl_negative_lemmas = [i for i in negative_lemmas if i not in positive_lemmas]\n",
    "\n",
    "#уравняем количество лемм, по которым смотрим, чтобы не было перевеса в какую-либо сторону\n",
    "\n",
    "if len(excl_positive_lemmas) > len(excl_negative_lemmas):\n",
    "    excl_positive_lemmas = excl_positive_lemmas[:len(excl_negative_lemmas)]\n",
    "else:\n",
    "    excl_negative_lemmas = excl_negative_lemmas[:len(excl_positive_lemmas)]\n",
    "    \n",
    "assert len(excl_negative_lemmas) == len(excl_positive_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tone(review, excl_positive_lemmas=excl_positive_lemmas, excl_negative_lemmas=excl_negative_lemmas):\n",
    "    \n",
    "    pos, neg = 0, 0\n",
    "    \n",
    "    review = review.lower().translate(str.maketrans('', '', punctuation))\n",
    "    review = re.sub('\\d+', '', review)\n",
    "    review = re.sub('\\s{2,}', ' ', review)\n",
    "    review = word_tokenize(review.lower())\n",
    "\n",
    "    for word in review:\n",
    "        lemma = morph.parse(word)[0].normal_form\n",
    "        if lemma in excl_positive_lemmas:\n",
    "            pos += 1\n",
    "        elif lemma in excl_negative_lemmas:\n",
    "            neg += 1\n",
    "    \n",
    "    if pos > neg:\n",
    "        tone = 'pos'\n",
    "    elif neg > pos:\n",
    "        tone = 'neg'\n",
    "    else:\n",
    "        tone = 'NA'\n",
    "            \n",
    "    return tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg   neg\n",
      "neg   neg\n",
      "neg   neg\n",
      "neg   pos\n",
      "neg   pos\n",
      "neg   pos\n",
      "neg   neg\n",
      "neg   pos\n",
      "neg   NA\n",
      "neg   pos\n",
      "pos   pos\n",
      "pos   neg\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   NA\n",
      "pos   neg\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "control_texts = negative_reviews[190:] + positive_reviews[190:] # данные, на которых будем проверять\n",
    "assert len(control_texts) == 20\n",
    "\n",
    "control_tones = [\"neg\"]*10 + [\"pos\"]*10\n",
    "\n",
    "tones = []\n",
    "\n",
    "for text in control_texts:\n",
    "    tones.append(detect_tone(text))\n",
    "    \n",
    "for i in range(20):\n",
    "    print(control_tones[i], ' ', tones[i])\n",
    "    \n",
    "print(accuracy_score(tones, control_tones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность чуть больше половины, что не очень хорошо, учитывая, что рандомным распределением мы могли бы получить эту самую половину. Возможно, что дело во входных данных: всё-таки фильмы, даже если они все одного жанра, достаточно разные, поэтому я попыталась сузить зону изучения до одного фильма. \n",
    "\n",
    "Тогда я взяла отзывы на «Отряд самоубийц», поскольку у него много как хороших, так и плохих (>200). Дальше будет то же самое, изменятся только отзывы и чуть-чуть их сбор (то есть кода нового не будет), посмотрим, будет ли так лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(rev_links):    \n",
    "    \n",
    "    reviews = []\n",
    "    #c = 0\n",
    "    \n",
    "    for film_reviews in tqdm(rev_links):\n",
    "        \n",
    "        #sleep(uniform(30, 50))\n",
    "        \n",
    "        headers = {'User-Agent': ua.random}\n",
    "        r = requests.get(film_reviews, headers=headers)        \n",
    "        soup = BeautifulSoup(r.text)\n",
    "\n",
    "        reviews += soup.find_all('span', {'class':'_reachbanner_'})\n",
    "\n",
    "        #for i in range(10): # на одной странице 10 отзывов\n",
    "        #    reviews[c*10+i] = re.sub(\"<.*?>|\\s{1,}\", \" \", str(reviews[c*10+i]))\n",
    "         \n",
    "        for i in range(len(reviews)): # на одной странице все отзывы\n",
    "            reviews[i] = re.sub(\"<.*?>|\\s{1,}\", \" \", str(reviews[i]))\n",
    "             \n",
    "        #c += 1\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSq_positive_rev_links = [\"https://www.kinopoisk.ru/film/468522/reviews/ord/rating/status/good/perpage/200/\"]\n",
    "SSq_negative_rev_links = [\"https://www.kinopoisk.ru/film/468522/reviews/ord/rating/status/bad/perpage/200/\"]\n",
    "\n",
    "# Отряд самоубийц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "SSq_negative_reviews = get_reviews(SSq_negative_rev_links)\n",
    "SSq_positive_reviews = get_reviews(SSq_positive_rev_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SSq_negative_reviews), len(SSq_positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSq_negative_lemmas_counter = get_lemmas_counter(SSq_negative_reviews[:190])\n",
    "SSq_positive_lemmas_counter = get_lemmas_counter(SSq_positive_reviews[:190])\n",
    "\n",
    "SSq_total_neg_counter = remove_rare(SSq_negative_lemmas_counter)\n",
    "SSq_total_pos_counter = remove_rare(SSq_positive_lemmas_counter)\n",
    "\n",
    "SSq_positive_lemmas = [i[0] for i in SSq_total_pos_counter]\n",
    "SSq_negative_lemmas = [i[0] for i in SSq_total_neg_counter]\n",
    "\n",
    "SSq_excl_positive_lemmas = [i for i in SSq_positive_lemmas if i not in SSq_negative_lemmas]\n",
    "SSq_excl_negative_lemmas = [i for i in SSq_negative_lemmas if i not in SSq_positive_lemmas]\n",
    "\n",
    "if len(SSq_excl_positive_lemmas) > len(SSq_excl_negative_lemmas):\n",
    "    SSq_excl_positive_lemmas = SSq_excl_positive_lemmas[:len(SSq_excl_negative_lemmas)]\n",
    "else:\n",
    "    SSq_excl_negative_lemmas = SSq_excl_negative_lemmas[:len(SSq_excl_positive_lemmas)]\n",
    "    \n",
    "assert len(SSq_excl_negative_lemmas) == len(SSq_excl_positive_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg   neg\n",
      "neg   neg\n",
      "neg   pos\n",
      "neg   neg\n",
      "neg   neg\n",
      "neg   pos\n",
      "neg   neg\n",
      "neg   pos\n",
      "neg   neg\n",
      "neg   NA\n",
      "pos   pos\n",
      "pos   neg\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   neg\n",
      "pos   neg\n",
      "pos   pos\n",
      "pos   pos\n",
      "pos   pos\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "SSq_control_texts = SSq_negative_reviews[190:] + SSq_positive_reviews[190:]\n",
    "assert len(SSq_control_texts) == 20\n",
    "\n",
    "control_tones = [\"neg\"]*10 + [\"pos\"]*10\n",
    "\n",
    "tones = []\n",
    "\n",
    "for text in SSq_control_texts:\n",
    "    tones.append(detect_tone(text, SSq_excl_positive_lemmas, SSq_excl_negative_lemmas))\n",
    "    \n",
    "for i in range(20):\n",
    "    print(control_tones[i], ' ', tones[i])\n",
    "    \n",
    "print(accuracy_score(tones, control_tones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, точность повысилась, хотя и недостаточно для того, чтобы считать результат достаточно хорошим. Тем не менее, как мне кажется, это всё-таки показывает, что чем ýже тема, на которую написаны отзывы, тем проще научиться определять их тон."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как можно это улучшить\n",
    "\n",
    "В первую очередь, нужно больше данных. Проблема возникает в том, что даже для того, чтобы было достаточно информации по одному фильму, мне пришлось взять одну из самых комментируемых картин на Кинопоиске, то есть для менее популярных фильмов даже такого качества опеределения с таким подходом вряд ли удастся добиться. Тем не менее, в имеющихся условиях, можно почистить данные, например, отобрав только прилагательные и наречия, поскольку они чаще всего и выражают субъективную точку зрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['абсолютно',\n",
       "  'час',\n",
       "  'диалог',\n",
       "  'логика',\n",
       "  'старый',\n",
       "  'например',\n",
       "  'видимо',\n",
       "  'отзыв',\n",
       "  'попытка',\n",
       "  'мать',\n",
       "  'положительный',\n",
       "  'плюс',\n",
       "  'глупый',\n",
       "  'както',\n",
       "  'рецензия',\n",
       "  'линия',\n",
       "  'банальный',\n",
       "  'поведение',\n",
       "  'никак',\n",
       "  'картинка'],\n",
       " ['настоящий',\n",
       "  'джеймс',\n",
       "  'ван',\n",
       "  'отличный',\n",
       "  'весьма',\n",
       "  'снять',\n",
       "  'сила',\n",
       "  'заклятие',\n",
       "  'шьямалан',\n",
       "  'создать',\n",
       "  'несмотря',\n",
       "  'молодой',\n",
       "  'душа',\n",
       "  'странный',\n",
       "  'завет',\n",
       "  'отметить',\n",
       "  'удаться',\n",
       "  'реинкарнация',\n",
       "  'день',\n",
       "  'современный'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excl_negative_lemmas[:20], excl_positive_lemmas[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди топ-20 лемм обоих окрасов, как видно, настроение передаётся именно прилагательными и наречиями («глупый», «банальный», «старый» (?) vs «отличный», «современный», «молодой» (?) или даже «никак» vs «весьма»)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё можно было бы попробовать учитывать вес слова в словаре «окрашенных» слов при подсчёте тех или иных лемм. То есть, например, если в отзыве самая частая положительная лемма 5 раз, и 5 разных лемм из отрицательного словаря, которые не входят даже в топ-20, то это учитывается в равной степени, хотя можно (и, возможно, нужно) было бы это считать как перевес в сторону положительного."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вообще мне кажется, что в фильмами в принципе сложнее, чем с, например, товарами — тут нет объективных критериев «плохо» и «хорошо». А ещё у Кинопоиска не различаются «сильно» отрицательные и «немного» отрицательные отзывы, как могло бы быть, если бы у них была унифицированная система рейтинга, скажем, от 1 до 5 или от 1 до 10, где можн было бы брать крайности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
